{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1417276,"sourceType":"datasetVersion","datasetId":826739},{"sourceId":11047024,"sourceType":"datasetVersion","datasetId":6881602}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load the Dataset","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Installing the Libraries","metadata":{}},{"cell_type":"markdown","source":"# Converting TACO Dataset to YOLO Format and Training YOLOv8\n\n## Overview\n\nThis notebook converts the TACO (Trash Annotations in Context) dataset to the YOLO format and trains a YOLOv8 model for waste detection. The TACO dataset contains annotated images of litter in diverse real-world environments, making it useful for object detection tasks related to waste classification.\n\n## Steps Involved\n\n### 1. Convert TACO Annotations to YOLO Format\n\nThe provided function convert_taco_to_yolo reads the JSON annotations from the TACO dataset and converts them into the YOLO format. This includes:\n\n- Extracting image and annotation details.\n\n- Splitting the dataset into training (80%) and validation (20%) subsets.\n\n- Saving images and their corresponding label files in YOLO format.\n\n### 2. Generate data.yaml\n\nA data.yaml file is created to define the dataset's path, number of classes, and class names. This file is essential for training YOLO models.\n\n### 3. Train YOLOv8\n\nWe use the Ultralytics YOLOv8 model (yolov8n.pt) to train on the converted dataset. The model is trained for 50 epochs with an image size of 640x640 pixels.\n\n## Implementation\n\n### Data Conversion\n\nThe function convert_taco_to_yolo performs the following:\n\n- Loads the annotations JSON file.\n\n- Creates directories for training and validation images and labels.\n\n- Copies images to respective directories.\n\n- Converts bounding box coordinates from COCO format (x, y, width, height) to YOLO format (x_center, y_center, width, height as fractions of image dimensions).\n\n- Saves the annotations in .txt format with class IDs.\n\n### Training\n\n- The YOLO class from ultralytics is used to train the YOLOv8 model.\n\n- The training runs for 50 epochs using the dataset defined in data.yaml.\n\n- Results, including loss metrics and mAP (mean Average Precision), can be analyzed for performance evaluation.\n\n## Expected Outcome\n\nAfter training, the YOLOv8 model will be capable of detecting waste in images. The trained weights can be used for inference on new images or deployed on edge devices for real-time waste detection.\n\n## Potential Applications\n\n- Waste management and recycling automation\n\n- Environmental monitoring\n\n- Smart city initiatives for cleaner public spaces\n\nThis notebook provides an efficient pipeline for converting the TACO dataset into YOLO format and training a robust object detection model.\n\n","metadata":{}},{"cell_type":"code","source":"!pip install -U ultralytics\nimport ultralytics\nultralytics.checks()\n\nimport json\nimport os\nfrom sklearn.model_selection import train_test_split\nimport shutil","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nfrom sklearn.model_selection import train_test_split\nimport shutil\nimport numpy as np\nfrom ultralytics import YOLO\n\ndef convert_taco_to_yolo(json_path, image_root_dir, output_dir):\n    with open(json_path, 'r') as f:\n        data = json.load(f)\n\n    images = data['images']\n    annotations = data['annotations']\n    categories = data['categories']\n\n    os.makedirs(os.path.join(output_dir, 'images/train'), exist_ok=True)\n    os.makedirs(os.path.join(output_dir, 'images/val'), exist_ok=True)\n    os.makedirs(os.path.join(output_dir, 'labels/train'), exist_ok=True)\n    os.makedirs(os.path.join(output_dir, 'labels/val'), exist_ok=True)\n\n    image_ids = [img['id'] for img in images]\n    train_ids, val_ids = train_test_split(image_ids, test_size=0.2, random_state=42)\n    image_id_to_filename = {img['id']: img['file_name'] for img in images}\n\n    for img in images:\n        img_id = img['id']\n        filename = img['file_name']\n        img_width = img['width']\n        img_height = img['height']\n\n        if img_id in train_ids:\n            image_dir = os.path.join(output_dir, 'images/train')\n            label_dir = os.path.join(output_dir, 'labels/train')\n        else:\n            image_dir = os.path.join(output_dir, 'images/val')\n            label_dir = os.path.join(output_dir, 'labels/val')\n\n        full_image_path = os.path.join(image_root_dir, filename)\n        if not os.path.exists(full_image_path):\n            print(f\"Warning: Image {full_image_path} not found.\")\n            continue\n        shutil.copy(full_image_path, os.path.join(image_dir, os.path.basename(filename)))\n\n        label_file = os.path.join(label_dir, os.path.basename(filename).replace('.jpg', '.txt').replace('.JPG', '.txt'))\n        with open(label_file, 'w') as lf:\n            for ann in annotations:\n                if ann['image_id'] == img_id:\n                    category_id = ann['category_id']\n                    bbox = ann['bbox']\n                    x_center = (bbox[0] + bbox[2] / 2) / img_width\n                    y_center = (bbox[1] + bbox[3] / 2) / img_height\n                    width = bbox[2] / img_width\n                    height = bbox[3] / img_height\n\n                    line = f\"{category_id} {x_center} {y_center} {width} {height}\"\n\n                    # Nếu có segmentation, thêm vào YOLOv8-seg format\n                    if 'segmentation' in ann and isinstance(ann['segmentation'], list):\n                        for seg in ann['segmentation']:\n                            seg_points = np.array(seg, dtype=float).reshape(-1, 2)\n                            seg_points[:, 0] /= img_width\n                            seg_points[:, 1] /= img_height\n                            seg_points_flat = \" \".join(map(str, seg_points.flatten()))\n                            line += f\" {seg_points_flat}\"\n                    lf.write(line + \"\\n\")\n\n# Gọi hàm\noutput_yolo_dir = '/kaggle/working/taco_yolo'\nimage_root_dir = '/kaggle/input/tacotrashdataset/data'\nconvert_taco_to_yolo('/kaggle/input/tacotrashdataset/data/annotations.json', image_root_dir, output_yolo_dir)\n\n# Tạo file data.yaml\nwith open('/kaggle/working/taco_yolo/data.yaml', 'w') as f:\n    f.write(f\"train: {os.path.abspath('/kaggle/working/taco_yolo/images/train')}\\n\")\n    f.write(f\"val: {os.path.abspath('/kaggle/working/taco_yolo/images/val')}\\n\")\n    f.write(\"nc: 60\\n\")\n    categories = json.load(open('/kaggle/input/tacotrashdataset/data/annotations.json', 'r'))['categories']\n    f.write(\"names: \" + str([cat['name'] for cat in categories]) + \"\\n\")\n\n# Train YOLOv8-seg\nmodel = YOLO('yolov8m-seg.pt')\nresults = model.train(data='/kaggle/working/taco_yolo/data.yaml', epochs=50, imgsz=640, project='/kaggle/working/runs', name='taco_train',augment=True,)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference on Validation Images\n\n## Run Inference: Use the trained model to make predictions on the validation images.","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\nimport cv2\nimport os\n\n# Load the trained model\nmodel = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n\n# Directory containing validation images\nval_images_dir = '/kaggle/working/taco_yolo/images/val'\n\n# Directory to save the results.\nresults_dir = '/kaggle/working/inference_results'\nos.makedirs(results_dir, exist_ok=True)\n\n# Iterate over validation images\nfor filename in os.listdir(val_images_dir):\n    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n        image_path = os.path.join(val_images_dir, filename)\n        image = cv2.imread(image_path)\n\n        # Perform inference\n        results = model(image)\n\n        # Visualize results\n        annotated_image = results[0].plot()\n\n        # Save annotated image\n        output_path = os.path.join(results_dir, f'annotated_{filename}')\n        cv2.imwrite(output_path, annotated_image)\n\nprint(f\"Inference results saved to {results_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport os\nfrom ultralytics import YOLO\n\n# Đường dẫn model đã train\nmodel_path = '/kaggle/working/runs/taco_train/weights/best.pt'\nmodel = YOLO(model_path)\n\n# Đánh giá model\nmetrics = model.val(data='/kaggle/working/taco_yolo/data.yaml')\n\n# In các chỉ số chính\nprint(f\"mAP@0.5-0.95: {metrics.box.map:.4f}\")\nprint(f\"mAP@0.5: {metrics.box.map50:.4f}\")\nprint(f\"Precision: {metrics.results_dict['metrics/precision(B)']:.4f}\")\nprint(f\"Recall: {metrics.results_dict['metrics/recall(B)']:.4f}\")\n\n# F1-score (tự tính)\nprecision = metrics.results_dict['metrics/precision(B)']\nrecall = metrics.results_dict['metrics/recall(B)']\nf1_score = 2 * (precision * recall) / (precision + recall)\nprint(f\"F1-Score: {f1_score:.4f}\")\n\n# Đọc file kết quả huấn luyện\nresults_csv = '/kaggle/working/runs/taco_train/results.csv'\ndf = pd.read_csv(results_csv)\n\n# Biểu đồ Loss\nplt.figure(figsize=(10, 5))\nplt.plot(df[\"epoch\"], df[\"train/box_loss\"], label=\"Train Box Loss\")\nplt.plot(df[\"epoch\"], df[\"train/cls_loss\"], label=\"Train Class Loss\")\nplt.plot(df[\"epoch\"], df[\"val/box_loss\"], label=\"Val Box Loss\")\nplt.plot(df[\"epoch\"], df[\"val/cls_loss\"], label=\"Val Class Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss per Epoch\")\nplt.legend()\nplt.grid(True)\nplt.savefig(\"/kaggle/working/loss_curve.png\")\nplt.show()\n\n# Biểu đồ Precision & Recall\nplt.figure(figsize=(6, 5))\nplt.plot(df[\"epoch\"], df[\"metrics/precision(B)\"], label=\"Precision\")\nplt.plot(df[\"epoch\"], df[\"metrics/recall(B)\"], label=\"Recall\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Score\")\nplt.title(\"Precision and Recall over Epochs\")\nplt.legend()\nplt.grid(True)\nplt.savefig(\"/kaggle/working/precision_recall_curve.png\")\nplt.show()\n\n# Biểu đồ mAP\nplt.figure(figsize=(6, 5))\nplt.plot(df[\"epoch\"], df[\"metrics/mAP50(B)\"], label=\"mAP@0.5\")\nplt.plot(df[\"epoch\"], df[\"metrics/mAP50-95(B)\"], label=\"mAP@0.5:0.95\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"mAP\")\nplt.title(\"mAP over Epochs\")\nplt.legend()\nplt.grid(True)\nplt.savefig(\"/kaggle/working/map_curve.png\")\nplt.show()\n\n# Confusion matrix (YOLO tự sinh ra)\n# Nếu đã có file, chỉ cần hiển thị lại\nconf_path = '/kaggle/working/runs/taco_train/confusion_matrix.png'\nif os.path.exists(conf_path):\n    from PIL import Image\n    img = Image.open(conf_path)\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(\"Confusion Matrix (YOLO auto-generated)\")\n    plt.show()\nelse:\n    model.plot_confusion_matrix(save_dir='/kaggle/working/runs/taco_train/')\n    print(\"Confusion matrix saved in /kaggle/working/runs/taco_train/\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport cv2\nimport os\n\n# Load the trained model\nmodel = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n\n# Path to your test image (replace with your actual path)\nimage_path = '/kaggle/input/test-data/download.jpeg'  # Or '/kaggle/working/your_image.jpg'\n\n# Load the image\nimage = cv2.imread(image_path)\n\n# Perform inference\nresults = model(image)\n\n# Visualize results\nannotated_image = results[0].plot()\n\n# Save the annotated image\noutput_path = '/kaggle/working/annotated_your_image.jpeg' # or annotated_your_image.jpg\ncv2.imwrite(output_path, annotated_image)\n\nprint(f\"Inference results saved to {output_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport cv2\nimport os\n\n# Load the trained model\nmodel = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n\n# Path to your test image (replace with your actual path)\nimage_path = '/kaggle/input/test-data/download (1).jpeg'  # Or '/kaggle/working/your_image.jpg'\n\n# Load the image\nimage = cv2.imread(image_path)\n\n# Perform inference\nresults = model(image)\n\n# Visualize results\nannotated_image = results[0].plot()\n\n# Save the annotated image\noutput_path = '/kaggle/working/annotated_your_image1.jpeg' # or annotated_your_image.jpg\ncv2.imwrite(output_path, annotated_image)\n\nprint(f\"Inference results saved to {output_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/working/runs/taco_train/weights","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}