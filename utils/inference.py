# utils/inference.py
from ultralytics import YOLO
from PIL import Image
import numpy as np
import os

# Load model má»™t láº§n khi module Ä‘Æ°á»£c import
MODEL_PATH = os.path.join("models", "best.pt")
print(f"[INFO] Loading YOLO model from: {MODEL_PATH}")
model = YOLO(MODEL_PATH)
print("[INFO] Model loaded.")

# Báº£ng gá»£i Ã½ xá»­ lÃ½ (báº¡n cÃ³ thá»ƒ má»Ÿ rá»™ng)
RECYCLING_GUIDE = {
    "plastic": "â™»ï¸ TÃ¡i cháº¿ hoáº·c thu gom nhá»±a Ä‘Ãºng nÆ¡i quy Ä‘á»‹nh",
    "bottle": "â™»ï¸ Váº­t liá»‡u nhá»±a - rá»­a sáº¡ch trÆ°á»›c khi tÃ¡i cháº¿",
    "paper": "ðŸ“„ CÃ³ thá»ƒ tÃ¡i cháº¿, trÃ¡nh Ä‘á»ƒ Æ°á»›t",
    "cardboard": "ðŸ“¦ HÃ¬nh nhÆ° lÃ  bÃ¬a carton - tÃ¡i cháº¿ Ä‘Æ°á»£c",
    "metal": "ðŸ”© Thu gom bÃ¡n pháº¿ liá»‡u hoáº·c tÃ¡i cháº¿",
    "can": "ðŸ”© Lon kim loáº¡i - tÃ¡i cháº¿",
    "glass": "ðŸ§´ CÃ³ thá»ƒ tÃ¡i cháº¿, cáº§n rá»­a sáº¡ch",
    "organic": "ðŸŒ¿ DÃ¹ng lÃ m phÃ¢n compost há»¯u cÆ¡",
    "food": "ðŸŒ¿ RÃ¡c há»¯u cÆ¡ - á»§ compost",
    "battery": "âš ï¸ RÃ¡c nguy háº¡i - mang Ä‘áº¿n Ä‘iá»ƒm thu gom chuyÃªn biá»‡t",
    "electronic": "âš ï¸ Thiáº¿t bá»‹ Ä‘iá»‡n tá»­ - thu gom táº¡i Ä‘iá»ƒm thu há»“i",
    # máº·c Ä‘á»‹nh
    "other": "ðŸš® KhÃ´ng xÃ¡c Ä‘á»‹nh: bá» Ä‘Ãºng thÃ¹ng rÃ¡c hoáº·c kiá»ƒm tra thÃªm"
}

def _get_guide(label: str) -> str:
    lbl = label.lower()
    # tÃ¬m key khá»›p má»™t pháº§n
    for k in RECYCLING_GUIDE.keys():
        if k in lbl:
            return RECYCLING_GUIDE[k]
    return RECYCLING_GUIDE["other"]

def analyze_image(pil_image: Image.Image, conf_threshold: float = 0.25):
    """
    Input:
      - pil_image: PIL.Image opened from user upload
      - conf_threshold: ngÆ°á»¡ng confidence Ä‘á»ƒ giá»¯ detect
    Returns:
      - result_pil: PIL.Image cÃ³ bounding boxes (dÃ¹ng Ä‘á»ƒ hiá»ƒn thá»‹)
      - detections: list of dicts {label, confidence, guide}
    Ghi chÃº: Ä‘á»“ng thá»i in log ra console.
    """
    # cháº¡y dá»± Ä‘oÃ¡n (ultralytics YOLO)
    # báº¡n cÃ³ thá»ƒ thÃªm imgsz=640, device="cpu"/"0" náº¿u cáº§n
    results = model.predict(source=pil_image, conf=conf_threshold, verbose=False)
    result = results[0]

    detections = []
    boxes = getattr(result, "boxes", None)

    if boxes is not None and len(boxes) > 0:
        # boxes.cls, boxes.conf lÃ  tensors
        classes = boxes.cls.cpu().numpy().astype(int)
        confs = boxes.conf.cpu().numpy()
        names = model.names  # dict id->name
        for cls_id, conf in zip(classes, confs):
            label = names.get(int(cls_id), str(cls_id))
            guide = _get_guide(label)
            detections.append({
                "label": label,
                "confidence": float(conf),
                "guide": guide
            })
            # print log backend
            print(f"[DETECT] {label} - {conf*100:.1f}% -> {guide}")
    else:
        print("[DETECT] KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c Ä‘á»‘i tÆ°á»£ng nÃ o.")

    # result.plot() tráº£ numpy array (H x W x 3). CÃ³ thá»ƒ lÃ  BGR/RGB tÃ¹y phiÃªn báº£n.
    result_img = result.plot()  # numpy array
    # ensure convert to PIL Image and RGB
    try:
        import cv2
        # náº¿u mÃ u bá»‹ sai (nhiá»u kháº£ nÄƒng result.plot tráº£ BGR), chuyá»ƒn qua RGB
        if result_img.ndim == 3 and result_img.shape[2] == 3:
            result_img_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
        else:
            result_img_rgb = result_img
        result_pil = Image.fromarray(result_img_rgb)
    except Exception:
        # fallback: assume array[..., ::-1] náº¿u cáº§n, else just fromarray
        try:
            if result_img.ndim == 3 and result_img.shape[2] == 3:
                result_pil = Image.fromarray(result_img[..., ::-1])  # BGR->RGB attempt
            else:
                result_pil = Image.fromarray(result_img)
        except Exception as e:
            # cuá»‘i cÃ¹ng, tráº£ áº£nh input náº¿u khÃ´ng chuyá»ƒn Ä‘Æ°á»£c
            print(f"[WARN] KhÃ´ng convert Ä‘Æ°á»£c result_img sang PIL: {e}")
            result_pil = pil_image

    return result_pil, detections
